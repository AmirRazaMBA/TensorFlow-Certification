{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HDhfftMGc_i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uusvhUp9Gg37"
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow Datasets\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXZ44qIaG0Ru"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## Import the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaOTZxFzi48X"
   },
   "outputs": [],
   "source": [
    "num_train_examples = metadata.splits['train'].num_examples\n",
    "num_test_examples = metadata.splits['test'].num_examples\n",
    "print(\"Number of training examples: {}\".format(num_train_examples))\n",
    "print(\"Number of test examples:     {}\".format(num_test_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ES6uQoLKCaWr"
   },
   "outputs": [],
   "source": [
    "## Preprocess the data\n",
    "\n",
    "#The value of each pixel in the image data is an integer in the range `[0,255]`. \n",
    "#For the model to work properly, these values need to be normalized to the range `[0,1]`. \n",
    "#So here we create a normalization function, and then apply it to each image in the test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAsH3Zm-76pB"
   },
   "outputs": [],
   "source": [
    "def normalize(images, labels):\n",
    "  images = tf.cast(images, tf.float32)\n",
    "  images /= 255\n",
    "  return images, labels\n",
    "\n",
    "# The map function applies the normalize function to each element in the train\n",
    "# and test datasets\n",
    "train_dataset =  train_dataset.map(normalize)\n",
    "test_dataset  =  test_dataset.map(normalize)\n",
    "\n",
    "# The first time you use the dataset, the images will be loaded from disk\n",
    "# Caching will keep them in memory, making training faster\n",
    "train_dataset =  train_dataset.cache()\n",
    "test_dataset  =  test_dataset.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIQbEiJGXM-q"
   },
   "source": [
    "### Explore the processed data\n",
    "\n",
    "Let's plot an image to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSzE9l7PjHx0"
   },
   "outputs": [],
   "source": [
    "# Take a single image, and remove the color dimension by reshaping\n",
    "for image, label in test_dataset.take(1):\n",
    "  break\n",
    "image = image.numpy().reshape((28,28))\n",
    "\n",
    "# Plot the image - voila a piece of fashion clothing\n",
    "plt.figure()\n",
    "plt.imshow(image, cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee638AlnCaWz"
   },
   "source": [
    "Display the first 25 images from the *training set* and display the class name below each image. Verify that the data is in the correct format and we're ready to build and train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZTImqg_CaW1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "i = 0\n",
    "for (image, label) in test_dataset.take(25):\n",
    "    image = image.numpy().reshape((28,28))\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[label])\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function — An algorithm for measuring how far the model's outputs are from the desired output. The goal of training is this measures loss.\n",
    "#Optimizer —An algorithm for adjusting the inner parameters of the model in order to minimize loss.\n",
    "#Metrics —Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "First, we define the iteration behavior for the train dataset:\n",
    "1. Repeat forever by specifying `dataset.repeat()` (the `epochs` parameter described below limits how long we perform training).\n",
    "2. The `dataset.shuffle(60000)` randomizes the order so our model cannot learn anything from the order of the examples.\n",
    "3. And `dataset.batch(32)` tells `model.fit` to use batches of 32 images and labels when updating the model variables.\n",
    "\n",
    "Training is performed by calling the `model.fit` method:\n",
    "1. Feed the training data to the model using `train_dataset`.\n",
    "2. The model learns to associate images and labels.\n",
    "3. The `epochs=5` parameter limits training to 5 full iterations of the training dataset, so a total of 5 * 60000 = 300000 examples.\n",
    "\n",
    "(Don't worry about `steps_per_epoch`, the requirement to have this flag will soon be removed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_Dp8971McQ1"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvwvpA64CaW_"
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=10, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ZVOhugCaXA"
   },
   "source": [
    "As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.97 (or 97%) on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEw4bZgGCaXB"
   },
   "source": [
    "## Evaluate accuracy\n",
    "\n",
    "Next, compare how the model performs on the test dataset. Use all examples we have in the test dataset to assess accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\n",
    "print('Accuracy on test dataset:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWfgsmVXCaXG"
   },
   "source": [
    "As it turns out, the accuracy on the test dataset is smaller than the accuracy on the training dataset. This is completely normal, since the model was trained on the `train_dataset`. When the model sees images it has never seen during training, (that is, from the `test_dataset`), we can expect performance to go down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsoS7CPDCaXH"
   },
   "source": [
    "## Make predictions and explore\n",
    "\n",
    "With the model trained, we can use it to make predictions about some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ccoz4conNCpl"
   },
   "outputs": [],
   "source": [
    "for test_images, test_labels in test_dataset.take(1):\n",
    "  test_images = test_images.numpy()\n",
    "  test_labels = test_labels.numpy()\n",
    "  predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": [
    "predictions.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9Kk1voUCaXJ"
   },
   "source": [
    "Here, the model has predicted the probability of each label for each image in the testing set. Let's take a look at the first prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DmJEUinCaXK"
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hw1hgeSCaXN"
   },
   "source": [
    "A prediction is an array of 10 numbers. These describe the \"confidence\" of the model that the image corresponds to each of the 10 different articles of clothing. We can see which label has the highest confidence value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsqenuPnCaXO"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E51yS7iCCaXO"
   },
   "source": [
    "So the model is usually most confident that this image is a Shirt, or `class_names[6]`. Let's check the label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sd7Pgsu6CaXP"
   },
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygh2yYC972ne"
   },
   "source": [
    "We can graph this to look at the full set of 10 class predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvYmmrpIy6Y1"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_labels, images):\n",
    "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  \n",
    "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  \n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  \n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Ov9OFDMmOD"
   },
   "source": [
    "Let's look at the 0th image, predictions, and prediction array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko-uzOufSCSe"
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "Let's plot several images with their predictions. Correct prediction labels are blue and incorrect prediction labels are red. The number gives the percent (out of 100) for the predicted label. Note that it can be wrong even when very confident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted label, and the true label\n",
    "# Color correct predictions in blue, incorrect predictions in red\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions, test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R32zteKHCaXT"
   },
   "source": [
    "Finally, use the trained model to make a prediction about a single image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRJ7JU7JCaXT"
   },
   "outputs": [],
   "source": [
    "# Grab an image from the test dataset\n",
    "img = test_images[0]\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz3bVp21CaXV"
   },
   "source": [
    "`tf.keras` models are optimized to make predictions on a *batch*, or collection, of examples at once. So even though we're using a single image, we need to add it to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDFh5yF_CaXW"
   },
   "outputs": [],
   "source": [
    "# Add the image to a batch where it's the only member.\n",
    "img = np.array([img])\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ5wLTkcCaXY"
   },
   "source": [
    "Now predict the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_rzNSdrCaXY"
   },
   "outputs": [],
   "source": [
    "predictions_single = model.predict(img)\n",
    "\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ai-cpLjO-3A"
   },
   "outputs": [],
   "source": [
    "plot_value_array(0, predictions_single, test_labels)\n",
    "_ = plt.xticks(range(10), class_names, rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU1Y2OAMCaXb"
   },
   "source": [
    "`model.predict` returns a list of lists, one for each image in the batch of data. Grab the predictions for our (only) image in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tRmdq_8CaXb"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions_single[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "And, as before, the model predicts a label of 6 (shirt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KtnHECKZni_"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "Experiment with different models and see how the accuracy results differ. In particular change the following parameters:\n",
    "*   Set training epochs set to 1\n",
    "*   Number of neurons in the Dense layer following the Flatten one. For example, go really low (e.g. 10) in ranges up to 512 and see how accuracy changes\n",
    "*   Add additional Dense layers between the Flatten and the final Dense(10), experiment with different units in these layers\n",
    "*   Don't normalize the pixel values, and see the effect that has\n",
    "\n",
    "\n",
    "Remember to enable GPU to make everything run faster (Runtime -> Change runtime type -> Hardware accelerator -> GPU).\n",
    "Also, if you run into trouble, simply reset the entire environment and start from the beginning:\n",
    "*   Edit -> Clear all outputs\n",
    "*   Runtime -> Reset all runtimes"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "l04c01_image_classification_with_cnns.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
